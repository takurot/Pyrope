{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pyrope: Gemini-Driven Autonomous Vector Database\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/takurot/Pyrope/blob/main/example/pyrope_colab_demo.ipynb)\n",
                "\n",
                "Pyrope is a self-driving vector database that integrates **Microsoft Garnet** with **Google Gemini**. \n",
                "In this notebook, we will:\n",
                "1. Setup the Pyrope environment (.NET + Python).\n",
                "2. Generate gRPC code for the Sidecar.\n",
                "3. Start the AI Sidecar (Gemini-powered controller).\n",
                "4. Start the Garnet Server.\n",
                "5. Perform vector search and see Gemini's autonomous policy in action."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install .NET SDK (Required for Garnet)\n",
                "!wget https://dot.net/v1/dotnet-install.sh -O dotnet-install.sh\n",
                "!chmod +x dotnet-install.sh\n",
                "!./dotnet-install.sh --channel 8.0\n",
                "import os\n",
                "import sys\n",
                "os.environ[\"PATH\"] = f\"{os.environ['HOME']}/.dotnet:\" + os.environ[\"PATH\"]\n",
                "\n",
                "# Clone the repository (uses main branch by default)\n",
                "!rm -rf Pyrope\n",
                "!git clone https://github.com/takurot/Pyrope.git\n",
                "%cd Pyrope\n",
                "# !git checkout feature/gemini-cache-control # Uncomment if verifyng a specific branch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Python dependencies for AI Sidecar\n",
                "!{sys.executable} -m pip install grpcio grpcio-tools google-generativeai psutil redis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate gRPC Code\n",
                "We need to generate the Python gRPC stubs from the .proto file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Python gRPC code (Updated Path)\n",
                "# Using sys.executable to ensure we use the same environment\n",
                "!{sys.executable} -m grpc_tools.protoc -Isrc/Protos --python_out=src/Pyrope.AISidecar --grpc_python_out=src/Pyrope.AISidecar src/Protos/policy_service.proto"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configure Gemini API Key\n",
                "Set your Gemini API key from [Google AI Studio](https://aistudio.google.com/)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import getpass\n",
                "import os\n",
                "os.environ[\"GEMINI_API_KEY\"] = getpass.getpass(\"Enter your Gemini API Key: \")\n",
                "os.environ[\"LLM_POLICY_ENABLED\"] = \"true\"\n",
                "os.environ[\"GEMINI_MODEL_ID\"] = \"gemini-2.5-flash-lite\" # Or gemini-1.5-flash"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Launch Services"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile the server first to catch build errors\n",
                "!dotnet build src/Pyrope.GarnetServer --configuration Release"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import time\n",
                "import socket\n",
                "import sys\n",
                "\n",
                "def wait_for_port(port, timeout=30):\n",
                "    print(f\"Waiting for port {port}...\")\n",
                "    start = time.time()\n",
                "    while time.time() - start < timeout:\n",
                "        try:\n",
                "            with socket.create_connection((\"127.0.0.1\", port), timeout=1):\n",
                "                return True\n",
                "        except OSError:\n",
                "            time.sleep(1)\n",
                "    return False\n",
                "\n",
                "print(\"Starting AI Sidecar (logging to sidecar.log)...\")\n",
                "# Check if running first\n",
                "if 'sidecar_process' in locals() and sidecar_process.poll() is None:\n",
                "    print(\"Sidecar already running.\")\n",
                "else:\n",
                "    # Open a file for logging to avoid PIPE buffer issues and close file issues\n",
                "    sidecar_log_file = open(\"sidecar.log\", \"w\")\n",
                "    sidecar_process = subprocess.Popen(\n",
                "        [sys.executable, \"-u\", \"src/Pyrope.AISidecar/server.py\"],\n",
                "        stdout=sidecar_log_file, stderr=subprocess.STDOUT, text=True\n",
                "    )\n",
                "    # Give Sidecar a moment\n",
                "    time.sleep(2)\n",
                "\n",
                "print(\"Starting Garnet Server (Pyrope)...\")\n",
                "if 'server_process' in locals() and server_process.poll() is None:\n",
                "    print(\"Garnet Server already running.\")\n",
                "else:\n",
                "    # Redirect Garnet output to file as well to prevent buffer deadlock\n",
                "    garnet_log_file = open(\"garnet.log\", \"w\")\n",
                "    server_process = subprocess.Popen(\n",
                "        [\"dotnet\", \"run\", \"--project\", \"src/Pyrope.GarnetServer\", \"--configuration\", \"Release\", \"--no-build\", \"--\", \"--port\", \"6379\", \"--bind\", \"127.0.0.1\"],\n",
                "        env={**os.environ, \"Auth__Enabled\": \"false\", \"PYROPE_SIDECAR_ENDPOINT\": \"http://127.0.0.1:50051\", \"Sidecar__MetricsIntervalSeconds\": \"2\"},\n",
                "        stdout=garnet_log_file, stderr=subprocess.STDOUT, text=True\n",
                "    )\n",
                "\n",
                "if wait_for_port(6379, timeout=30):\n",
                "    print(\"✅ Services started successfully and port 6379 is open!\")\n",
                "else:\n",
                "    print(\"❌ Timed out waiting for Garnet Server.\")\n",
                "    if server_process.poll() is not None:\n",
                "        print(\"Server Process Exited. Check garnet.log\")\n",
                "    else:\n",
                "        print(\"Server Process is still running but port is not open.\")\n",
                "        server_process.terminate()\n",
                "    \n",
                "    if sidecar_process.poll() is not None:\n",
                "        print(\"Sidecar Process Exited.\")\n",
                "        sys.stdout.flush()\n",
                "        # Check logs immediately\n",
                "        !cat sidecar.log\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Run Vector Operations\n",
                "We use standard Redis client to interact with Pyrope's `VEC.*` commands."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import redis\n",
                "import json\n",
                "import random\n",
                "import struct\n",
                "\n",
                "# Connect with increased timeout\n",
                "r = redis.Redis(host='127.0.0.1', port=6379, decode_responses=False, socket_timeout=5)\n",
                "\n",
                "TENANT = \"colab_user\"\n",
                "INDEX = \"demo_index\"\n",
                "DIM = 32\n",
                "\n",
                "def float_list_to_binary(floats):\n",
                "    return struct.pack(f\"{len(floats)}f\", *floats)\n",
                "\n",
                "try:\n",
                "    print(\"Pinging server...\")\n",
                "    print(f\"Response: {r.ping()}\")\n",
                "\n",
                "    print(\"Adding vectors...\")\n",
                "    for i in range(50):\n",
                "        vec = [random.random() for _ in range(DIM)]\n",
                "        # VEC.ADD <tenant> <index> <id> VECTOR <blob> META <json>\n",
                "        r.execute_command(\"VEC.ADD\", TENANT, INDEX, f\"v{i}\", \"VECTOR\", float_list_to_binary(vec), \"META\", json.dumps({\"label\": i}))\n",
                "    print(\"Vectors added.\")\n",
                "\n",
                "    print(\"Performing search...\")\n",
                "    query = [random.random() for _ in range(DIM)]\n",
                "    # Correct Order: VEC.SEARCH <tenant> <index> TOPK <k> VECTOR <vec>\n",
                "    results = r.execute_command(\"VEC.SEARCH\", TENANT, INDEX, \"TOPK\", 5, \"VECTOR\", float_list_to_binary(query))\n",
                "    print(f\"Search Results: {results}\")\n",
                "\n",
                "    # Wait for metrics to be reported to Sidecar\n",
                "    print(\"\\n⏳ Waiting 10 seconds for metrics to be reported to Sidecar... (Metrics Interval is 2s)\")\n",
                "    time.sleep(10)\n",
                "    print(\"Done waiting. You can now check the logs.\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Check AI Sidecar Logs\n",
                "Let's see how Gemini is responding to the metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Flush file handles\n",
                "try:\n",
                "    sidecar_log_file.flush()\n",
                "    garnet_log_file.flush()\n",
                "except: pass\n",
                "\n",
                "print(\"--- Sidecar Logs ---\")\n",
                "!cat sidecar.log\n",
                "\n",
                "print(\"\\n--- Garnet Logs (Last 20 lines) ---\")\n",
                "!tail -n 20 garnet.log\n",
                "\n",
                "# Note: Processes are still running. \n",
                "# To stop them, run the Cleanup cell below."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Understanding the Logs\n",
                "\n",
                "In the **Sidecar Logs** above, look for the following sequence which indicates Gemini is controlling the cache:\n",
                "\n",
                "1.  **Metric Reporting**:\n",
                "    ```\n",
                "    Metrics: qps=0.50 miss_rate=1.00 latency_p99_ms=50.00 ... -> Policy(ttl=300)\n",
                "    ```\n",
                "    The Sidecar receives metrics from Garnet (high miss rate in this example).\n",
                "\n",
                "2.  **LLM Trigger**:\n",
                "    ```\n",
                "    INFO - Triggered async LLM update for key ...\n",
                "    ```\n",
                "    Since the metrics have changed (freshness check), the `LLMPolicyEngine` decides to ask Gemini for a new policy asynchronously.\n",
                "\n",
                "3.  **Gemini's Decision**:\n",
                "    ```\n",
                "    INFO - LLM Policy Updated ... PolicyConfig(admission_threshold=0.5, ttl_seconds=3600...)\n",
                "    ```\n",
                "    Gemini analyzes the metrics (high miss rate) and decides to **increase the TTL** (e.g., to 3600s) to keep data in cache longer and improve the hit rate."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Cleanup (Optional)\n",
                "Run this cell only when you are done with the demo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Stopping services...\")\n",
                "if 'sidecar_process' in locals() and sidecar_process.poll() is None:\n",
                "    sidecar_process.terminate()\n",
                "    sidecar_process.wait()\n",
                "\n",
                "if 'server_process' in locals() and server_process.poll() is None:\n",
                "    server_process.terminate()\n",
                "    server_process.wait()\n",
                "\n",
                "try:\n",
                "    sidecar_log_file.close()\n",
                "    garnet_log_file.close()\n",
                "except:\n",
                "    pass\n",
                "print(\"Services stopped.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}